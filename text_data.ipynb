{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd8bd31",
   "metadata": {},
   "source": [
    "## Alternative Vocabulary Options\n",
    "\n",
    "Instead of using only tokens from \"the-verdict.txt\", you can use more comprehensive English vocabularies:\n",
    "\n",
    "### Option 1: NLTK Words Corpus\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "english_words = set(words.words())\n",
    "```\n",
    "\n",
    "### Option 2: Pre-trained Tokenizers\n",
    "- **tiktoken** (OpenAI's tokenizer) - already in requirements.txt\n",
    "- **Hugging Face tokenizers** - BPE, WordPiece, SentencePiece\n",
    "- **spaCy** tokenizers\n",
    "\n",
    "### Option 3: Large Text Datasets\n",
    "- Common Crawl\n",
    "- Wikipedia dumps\n",
    "- Project Gutenberg\n",
    "- Google Books N-grams\n",
    "\n",
    "### Option 4: Word Frequency Lists\n",
    "- Google's 10,000 most common English words\n",
    "- Brown Corpus vocabulary\n",
    "- Oxford English Dictionary word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5570c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./files/the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9864e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20479"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b2df6",
   "metadata": {},
   "source": [
    "**Tokeninzing text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "338e0730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world', '!', 'This', 'is', 'a', 'test', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \"Hello world! This is a test.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "result = re.split(r'(\\s|[.,!])', text)\n",
    "result = [token for token in result if token.strip()]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "087ff57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import nltk\\nnltk.download('words')\\nfrom nltk.corpus import words\\nenglish_words = set(words.words())\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import nltk\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "english_words = set(words.words())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d33385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'HAD',\n",
       " 'always',\n",
       " 'thought',\n",
       " 'Jack',\n",
       " 'Gisburn',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'cheap',\n",
       " 'genius',\n",
       " '--',\n",
       " 'though',\n",
       " 'a',\n",
       " 'good',\n",
       " 'fellow',\n",
       " 'enough',\n",
       " '--',\n",
       " 'so',\n",
       " 'it',\n",
       " 'was',\n",
       " 'no',\n",
       " 'great',\n",
       " 'surprise',\n",
       " 'to',\n",
       " 'me',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'that',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'height',\n",
       " 'of',\n",
       " 'his',\n",
       " 'glory',\n",
       " ',',\n",
       " 'he',\n",
       " 'had',\n",
       " 'dropped',\n",
       " 'his',\n",
       " 'painting',\n",
       " ',',\n",
       " 'married',\n",
       " 'a',\n",
       " 'rich',\n",
       " 'widow',\n",
       " ',',\n",
       " 'and',\n",
       " 'established',\n",
       " 'himself',\n",
       " 'in',\n",
       " 'a',\n",
       " 'villa',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Riviera',\n",
       " '.',\n",
       " '(',\n",
       " 'Though',\n",
       " 'I',\n",
       " 'rather',\n",
       " 'thought',\n",
       " 'it',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'Rome',\n",
       " 'or',\n",
       " 'Florence',\n",
       " '.',\n",
       " ')',\n",
       " '\"',\n",
       " 'The',\n",
       " 'height',\n",
       " 'of',\n",
       " 'his',\n",
       " 'glory',\n",
       " '\"',\n",
       " '--',\n",
       " 'that',\n",
       " 'was',\n",
       " 'what',\n",
       " 'the',\n",
       " 'women',\n",
       " 'called',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'can',\n",
       " 'hear',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gideon',\n",
       " 'Thwing',\n",
       " '--',\n",
       " 'his',\n",
       " 'last',\n",
       " 'Chicago',\n",
       " 'sitter',\n",
       " '--',\n",
       " 'deploring',\n",
       " 'his',\n",
       " 'unaccountable',\n",
       " 'abdication',\n",
       " '.',\n",
       " '\"',\n",
       " 'Of',\n",
       " 'course',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'going',\n",
       " 'to',\n",
       " 'send',\n",
       " 'the',\n",
       " 'value',\n",
       " 'of',\n",
       " 'my',\n",
       " 'picture',\n",
       " \"'\",\n",
       " 'way',\n",
       " 'up',\n",
       " ';',\n",
       " 'but',\n",
       " 'I',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'think',\n",
       " 'of',\n",
       " 'that',\n",
       " ',',\n",
       " 'Mr',\n",
       " '.',\n",
       " 'Rickham',\n",
       " '--',\n",
       " 'the',\n",
       " 'loss',\n",
       " 'to',\n",
       " 'Arrt',\n",
       " 'is',\n",
       " 'all',\n",
       " 'I',\n",
       " 'think',\n",
       " 'of',\n",
       " '.',\n",
       " '\"',\n",
       " 'The',\n",
       " 'word',\n",
       " ',',\n",
       " 'on',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Thwing',\n",
       " \"'\",\n",
       " 's',\n",
       " 'lips',\n",
       " ',',\n",
       " 'multiplied',\n",
       " 'its',\n",
       " '_',\n",
       " 'rs',\n",
       " '_',\n",
       " 'as',\n",
       " 'though',\n",
       " 'they',\n",
       " 'were',\n",
       " 'reflected',\n",
       " 'in',\n",
       " 'an',\n",
       " 'endless',\n",
       " 'vista',\n",
       " 'of',\n",
       " 'mirrors',\n",
       " '.',\n",
       " 'And',\n",
       " 'it',\n",
       " 'was',\n",
       " 'not',\n",
       " 'only',\n",
       " 'the',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Thwings',\n",
       " 'who',\n",
       " 'mourned',\n",
       " '.',\n",
       " 'Had',\n",
       " 'not',\n",
       " 'the',\n",
       " 'exquisite',\n",
       " 'Hermia',\n",
       " 'Croft',\n",
       " ',',\n",
       " 'at',\n",
       " 'the',\n",
       " 'last',\n",
       " 'Grafton',\n",
       " 'Gallery',\n",
       " 'show',\n",
       " ',',\n",
       " 'stopped',\n",
       " 'me',\n",
       " 'before',\n",
       " 'Gisburn',\n",
       " \"'\",\n",
       " 's',\n",
       " '\"',\n",
       " 'Moon',\n",
       " '-',\n",
       " 'dancers',\n",
       " '\"',\n",
       " 'to',\n",
       " 'say',\n",
       " ',',\n",
       " 'with',\n",
       " 'tears',\n",
       " 'in',\n",
       " 'her',\n",
       " 'eyes',\n",
       " ':',\n",
       " '\"',\n",
       " 'We',\n",
       " 'shall',\n",
       " 'not',\n",
       " 'look',\n",
       " 'upon',\n",
       " 'its',\n",
       " 'like',\n",
       " 'again',\n",
       " '\"',\n",
       " '?',\n",
       " 'Well',\n",
       " '!',\n",
       " '--',\n",
       " 'even',\n",
       " 'through',\n",
       " 'the',\n",
       " 'prism',\n",
       " 'of',\n",
       " 'Hermia',\n",
       " \"'\",\n",
       " 's',\n",
       " 'tears',\n",
       " 'I',\n",
       " 'felt',\n",
       " 'able',\n",
       " 'to',\n",
       " 'face',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'with',\n",
       " 'equanimity',\n",
       " '.',\n",
       " 'Poor',\n",
       " 'Jack',\n",
       " 'Gisburn',\n",
       " '!',\n",
       " 'The',\n",
       " 'women',\n",
       " 'had',\n",
       " 'made',\n",
       " 'him',\n",
       " '--',\n",
       " 'it',\n",
       " 'was',\n",
       " 'fitting',\n",
       " 'that',\n",
       " 'they',\n",
       " 'should',\n",
       " 'mourn',\n",
       " 'him',\n",
       " '.',\n",
       " 'Among',\n",
       " 'his',\n",
       " 'own',\n",
       " 'sex',\n",
       " 'fewer',\n",
       " 'regrets',\n",
       " 'were',\n",
       " 'heard',\n",
       " ',',\n",
       " 'and',\n",
       " 'in',\n",
       " 'his',\n",
       " 'own',\n",
       " 'trade',\n",
       " 'hardly',\n",
       " 'a',\n",
       " 'murmur',\n",
       " '.',\n",
       " 'Professional',\n",
       " 'jealousy',\n",
       " '?',\n",
       " 'Perhaps',\n",
       " '.',\n",
       " 'If',\n",
       " 'it',\n",
       " 'were',\n",
       " ',',\n",
       " 'the',\n",
       " 'honour',\n",
       " 'of',\n",
       " 'the',\n",
       " 'craft',\n",
       " 'was',\n",
       " 'vindicated',\n",
       " 'by',\n",
       " 'little',\n",
       " 'Claude',\n",
       " 'Nutley',\n",
       " ',',\n",
       " 'who',\n",
       " ',',\n",
       " 'in',\n",
       " 'all',\n",
       " 'good',\n",
       " 'faith',\n",
       " ',',\n",
       " 'brought',\n",
       " 'out',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Burlington',\n",
       " 'a',\n",
       " 'very',\n",
       " 'handsome',\n",
       " '\"',\n",
       " 'obituary',\n",
       " '\"',\n",
       " 'on',\n",
       " 'Jack',\n",
       " '--',\n",
       " 'one',\n",
       " 'of',\n",
       " 'those',\n",
       " 'showy',\n",
       " 'articles',\n",
       " 'stocked',\n",
       " 'with',\n",
       " 'random',\n",
       " 'technicalities',\n",
       " 'that',\n",
       " 'I',\n",
       " 'have',\n",
       " 'heard',\n",
       " '(',\n",
       " 'I',\n",
       " 'won',\n",
       " \"'\",\n",
       " 't',\n",
       " 'say',\n",
       " 'by',\n",
       " 'whom',\n",
       " ')',\n",
       " 'compared',\n",
       " 'to',\n",
       " 'Gisburn',\n",
       " \"'\",\n",
       " 's',\n",
       " 'painting',\n",
       " '.',\n",
       " 'And',\n",
       " 'so',\n",
       " '--',\n",
       " 'his',\n",
       " 'resolve',\n",
       " 'being',\n",
       " 'apparently',\n",
       " 'irrevocable',\n",
       " '--',\n",
       " 'the',\n",
       " 'discussion',\n",
       " 'gradually',\n",
       " 'died',\n",
       " 'out',\n",
       " ',',\n",
       " 'and',\n",
       " ',',\n",
       " 'as',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Thwing',\n",
       " 'had',\n",
       " 'predicted',\n",
       " ',',\n",
       " 'the',\n",
       " 'price',\n",
       " 'of',\n",
       " '\"',\n",
       " 'Gisburns',\n",
       " '\"',\n",
       " 'went',\n",
       " 'up',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'not',\n",
       " 'till',\n",
       " 'three',\n",
       " 'years',\n",
       " 'later',\n",
       " 'that',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'course',\n",
       " 'of',\n",
       " 'a',\n",
       " 'few',\n",
       " 'weeks',\n",
       " \"'\",\n",
       " 'idling',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Riviera',\n",
       " ',',\n",
       " 'it',\n",
       " 'suddenly',\n",
       " 'occurred',\n",
       " 'to',\n",
       " 'me',\n",
       " 'to',\n",
       " 'wonder',\n",
       " 'why',\n",
       " 'Gisburn',\n",
       " 'had',\n",
       " 'given',\n",
       " 'up',\n",
       " 'his',\n",
       " 'painting',\n",
       " '.',\n",
       " 'On',\n",
       " 'reflection',\n",
       " ',',\n",
       " 'it',\n",
       " 'really',\n",
       " 'was',\n",
       " 'a',\n",
       " 'tempting',\n",
       " 'problem',\n",
       " '.',\n",
       " 'To',\n",
       " 'accuse',\n",
       " 'his',\n",
       " 'wife',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'too',\n",
       " 'easy',\n",
       " '--',\n",
       " 'his',\n",
       " 'fair',\n",
       " 'sitters',\n",
       " 'had',\n",
       " 'been',\n",
       " 'denied',\n",
       " 'the',\n",
       " 'solace',\n",
       " 'of',\n",
       " 'saying',\n",
       " 'that',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " 'had',\n",
       " '\"',\n",
       " 'dragged',\n",
       " 'him',\n",
       " 'down',\n",
       " '.',\n",
       " '\"',\n",
       " 'For',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " '--',\n",
       " 'as',\n",
       " 'such',\n",
       " '--',\n",
       " 'had',\n",
       " 'not',\n",
       " 'existed',\n",
       " 'till',\n",
       " 'nearly',\n",
       " 'a',\n",
       " 'year',\n",
       " 'after',\n",
       " 'Jack',\n",
       " \"'\",\n",
       " 's',\n",
       " 'resolve',\n",
       " 'had',\n",
       " 'been',\n",
       " 'taken',\n",
       " '.',\n",
       " 'It',\n",
       " 'might',\n",
       " 'be',\n",
       " 'that',\n",
       " 'he',\n",
       " 'had',\n",
       " 'married',\n",
       " 'her',\n",
       " '--',\n",
       " 'since',\n",
       " 'he',\n",
       " 'liked',\n",
       " 'his',\n",
       " 'ease',\n",
       " '--',\n",
       " 'because',\n",
       " 'he',\n",
       " 'didn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'want',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'painting',\n",
       " ';',\n",
       " 'but',\n",
       " 'it',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'prove',\n",
       " 'that',\n",
       " 'he',\n",
       " 'had',\n",
       " 'given',\n",
       " 'up',\n",
       " 'his',\n",
       " 'painting',\n",
       " 'because',\n",
       " 'he',\n",
       " 'had',\n",
       " 'married',\n",
       " 'her',\n",
       " '.',\n",
       " 'Of',\n",
       " 'course',\n",
       " ',',\n",
       " 'if',\n",
       " 'she',\n",
       " 'had',\n",
       " 'not',\n",
       " 'dragged',\n",
       " 'him',\n",
       " 'down',\n",
       " ',',\n",
       " 'she',\n",
       " 'had',\n",
       " 'equally',\n",
       " ',',\n",
       " 'as',\n",
       " 'Miss',\n",
       " 'Croft',\n",
       " 'contended',\n",
       " ',',\n",
       " 'failed',\n",
       " 'to',\n",
       " '\"',\n",
       " 'lift',\n",
       " 'him',\n",
       " 'up',\n",
       " '\"',\n",
       " '--',\n",
       " 'she',\n",
       " 'had',\n",
       " 'not',\n",
       " 'led',\n",
       " 'him',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'easel',\n",
       " '.',\n",
       " 'To',\n",
       " 'put',\n",
       " 'the',\n",
       " 'brush',\n",
       " 'into',\n",
       " 'his',\n",
       " 'hand',\n",
       " 'again',\n",
       " '--',\n",
       " 'what',\n",
       " 'a',\n",
       " 'vocation',\n",
       " 'for',\n",
       " 'a',\n",
       " 'wife',\n",
       " '!',\n",
       " 'But',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " 'appeared',\n",
       " 'to',\n",
       " 'have',\n",
       " 'disdained',\n",
       " 'it',\n",
       " '--',\n",
       " 'and',\n",
       " 'I',\n",
       " 'felt',\n",
       " 'it',\n",
       " 'might',\n",
       " 'be',\n",
       " 'interesting',\n",
       " 'to',\n",
       " 'find',\n",
       " 'out',\n",
       " 'why',\n",
       " '.',\n",
       " 'The',\n",
       " 'desultory',\n",
       " 'life',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Riviera',\n",
       " 'lends',\n",
       " 'itself',\n",
       " 'to',\n",
       " 'such',\n",
       " 'purely',\n",
       " 'academic',\n",
       " 'speculations',\n",
       " ';',\n",
       " 'and',\n",
       " 'having',\n",
       " ',',\n",
       " 'on',\n",
       " 'my',\n",
       " 'way',\n",
       " 'to',\n",
       " 'Monte',\n",
       " 'Carlo',\n",
       " ',',\n",
       " 'caught',\n",
       " 'a',\n",
       " 'glimpse',\n",
       " 'of',\n",
       " 'Jack',\n",
       " \"'\",\n",
       " 's',\n",
       " 'balustraded',\n",
       " 'terraces',\n",
       " 'between',\n",
       " 'the',\n",
       " 'pines',\n",
       " ',',\n",
       " 'I',\n",
       " 'had',\n",
       " 'myself',\n",
       " 'borne',\n",
       " 'thither',\n",
       " 'the',\n",
       " 'next',\n",
       " 'day',\n",
       " '.',\n",
       " 'I',\n",
       " 'found',\n",
       " 'the',\n",
       " 'couple',\n",
       " 'at',\n",
       " 'tea',\n",
       " 'beneath',\n",
       " 'their',\n",
       " 'palm',\n",
       " '-',\n",
       " 'trees',\n",
       " ';',\n",
       " 'and',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " \"'\",\n",
       " 's',\n",
       " 'welcome',\n",
       " 'was',\n",
       " 'so',\n",
       " 'genial',\n",
       " 'that',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'ensuing',\n",
       " 'weeks',\n",
       " ',',\n",
       " 'I',\n",
       " 'claimed',\n",
       " 'it',\n",
       " 'frequently',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'not',\n",
       " 'that',\n",
       " 'my',\n",
       " 'hostess',\n",
       " 'was',\n",
       " '\"',\n",
       " 'interesting',\n",
       " '\"',\n",
       " ':',\n",
       " 'on',\n",
       " 'that',\n",
       " 'point',\n",
       " 'I',\n",
       " 'could',\n",
       " 'have',\n",
       " 'given',\n",
       " 'Miss',\n",
       " 'Croft',\n",
       " 'the',\n",
       " 'fullest',\n",
       " 'reassurance',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'just',\n",
       " 'because',\n",
       " 'she',\n",
       " 'was',\n",
       " '_',\n",
       " 'not',\n",
       " '_',\n",
       " 'interesting',\n",
       " '--',\n",
       " 'if',\n",
       " 'I',\n",
       " 'may',\n",
       " 'be',\n",
       " 'pardoned',\n",
       " 'the',\n",
       " 'bull',\n",
       " '--',\n",
       " 'that',\n",
       " 'I',\n",
       " 'found',\n",
       " 'her',\n",
       " 'so',\n",
       " '.',\n",
       " 'For',\n",
       " 'Jack',\n",
       " ',',\n",
       " 'all',\n",
       " 'his',\n",
       " 'life',\n",
       " ',',\n",
       " 'had',\n",
       " 'been',\n",
       " 'surrounded',\n",
       " 'by',\n",
       " 'interesting',\n",
       " 'women',\n",
       " ':',\n",
       " 'they',\n",
       " 'had',\n",
       " 'fostered',\n",
       " 'his',\n",
       " 'art',\n",
       " ',',\n",
       " 'it',\n",
       " 'had',\n",
       " 'been',\n",
       " 'reared',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hot',\n",
       " '-',\n",
       " 'house',\n",
       " 'of',\n",
       " 'their',\n",
       " 'adulation',\n",
       " '.',\n",
       " 'And',\n",
       " 'it',\n",
       " 'was',\n",
       " 'therefore',\n",
       " 'instructive',\n",
       " 'to',\n",
       " 'note',\n",
       " 'what',\n",
       " 'effect',\n",
       " 'the',\n",
       " '\"',\n",
       " 'deadening',\n",
       " 'atmosphere',\n",
       " 'of',\n",
       " 'mediocrity',\n",
       " '\"',\n",
       " '(',\n",
       " 'I',\n",
       " 'quote',\n",
       " 'Miss',\n",
       " 'Croft',\n",
       " ')',\n",
       " 'was',\n",
       " 'having',\n",
       " 'on',\n",
       " 'him',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " 'was',\n",
       " 'rich',\n",
       " ';',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'immediately',\n",
       " 'perceptible',\n",
       " 'that',\n",
       " 'her',\n",
       " 'husband',\n",
       " 'was',\n",
       " 'extracting',\n",
       " 'from',\n",
       " 'this',\n",
       " 'circumstance',\n",
       " 'a',\n",
       " 'delicate',\n",
       " 'but',\n",
       " 'substantial',\n",
       " 'satisfaction',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " ',',\n",
       " 'as',\n",
       " 'a',\n",
       " 'rule',\n",
       " ',',\n",
       " 'the',\n",
       " 'people',\n",
       " 'who',\n",
       " 'scorn',\n",
       " 'money',\n",
       " 'who',\n",
       " 'get',\n",
       " 'most',\n",
       " 'out',\n",
       " 'of',\n",
       " 'it',\n",
       " ';',\n",
       " 'and',\n",
       " 'Jack',\n",
       " \"'\",\n",
       " 's',\n",
       " 'elegant',\n",
       " 'disdain',\n",
       " 'of',\n",
       " 'his',\n",
       " 'wife',\n",
       " \"'\",\n",
       " 's',\n",
       " 'big',\n",
       " 'balance',\n",
       " 'enabled',\n",
       " 'him',\n",
       " ',',\n",
       " 'with',\n",
       " 'an',\n",
       " 'appearance',\n",
       " 'of',\n",
       " 'perfect',\n",
       " 'good',\n",
       " '-',\n",
       " 'breeding',\n",
       " ',',\n",
       " 'to',\n",
       " 'transmute',\n",
       " 'it',\n",
       " 'into',\n",
       " 'objects',\n",
       " 'of',\n",
       " 'art',\n",
       " 'and',\n",
       " 'luxury',\n",
       " '.',\n",
       " 'To',\n",
       " 'the',\n",
       " 'latter',\n",
       " ',',\n",
       " 'I',\n",
       " 'must',\n",
       " 'add',\n",
       " ',',\n",
       " 'he',\n",
       " 'remained',\n",
       " 'relatively',\n",
       " 'indifferent',\n",
       " ';',\n",
       " 'but',\n",
       " 'he',\n",
       " 'was',\n",
       " 'buying',\n",
       " 'Renaissance',\n",
       " 'bronzes',\n",
       " 'and',\n",
       " 'eighteenth',\n",
       " '-',\n",
       " 'century',\n",
       " 'pictures',\n",
       " 'with',\n",
       " 'a',\n",
       " 'discrimination',\n",
       " 'that',\n",
       " 'bespoke',\n",
       " 'the',\n",
       " 'amplest',\n",
       " 'resources',\n",
       " '.',\n",
       " '\"',\n",
       " 'Money',\n",
       " \"'\",\n",
       " 's',\n",
       " 'only',\n",
       " 'excuse',\n",
       " 'is',\n",
       " 'to',\n",
       " 'put',\n",
       " 'beauty',\n",
       " 'into',\n",
       " 'circulation',\n",
       " ',',\n",
       " '\"',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'axioms',\n",
       " 'he',\n",
       " 'laid',\n",
       " 'down',\n",
       " 'across',\n",
       " 'the',\n",
       " 'Sevres',\n",
       " 'and',\n",
       " 'silver',\n",
       " 'of',\n",
       " 'an',\n",
       " 'exquisitely',\n",
       " 'appointed',\n",
       " 'luncheon',\n",
       " '-',\n",
       " 'table',\n",
       " ',',\n",
       " 'when',\n",
       " ',',\n",
       " 'on',\n",
       " 'a',\n",
       " 'later',\n",
       " 'day',\n",
       " ',',\n",
       " 'I',\n",
       " 'had',\n",
       " 'again',\n",
       " 'run',\n",
       " 'over',\n",
       " 'from',\n",
       " 'Monte',\n",
       " 'Carlo',\n",
       " ';',\n",
       " 'and',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " ',',\n",
       " 'beaming',\n",
       " 'on',\n",
       " 'him',\n",
       " ',',\n",
       " 'added',\n",
       " 'for',\n",
       " 'my',\n",
       " 'enlightenment',\n",
       " ':',\n",
       " '\"',\n",
       " 'Jack',\n",
       " 'is',\n",
       " 'so',\n",
       " 'morbidly',\n",
       " 'sensitive',\n",
       " 'to',\n",
       " 'every',\n",
       " 'form',\n",
       " 'of',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = re.split(r'(--|[,.;:?_!\"()\\'\\s-])', raw_text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dbb99c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4766"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprossed = result\n",
    "len(preprossed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cab394",
   "metadata": {},
   "source": [
    "## **CONVERTING THE TOKENS INTO TOKEN IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6390c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = sorted(set(preprossed))\n",
    "vocab_size = len(all_tokens)\n",
    "vocab = {token: integer for integer, token in enumerate(all_tokens)}\n",
    "inverse_vocab = {integer: token for token, integer in vocab.items()}\n",
    "token_ids = [vocab[token] for token in preprossed]\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57fe4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    \"\"\"\n",
    "    A simple tokenizer to convert text to a sequence of integer IDs and back.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab: dict):\n",
    "        \"\"\"\n",
    "        Initializes the tokenizer with a vocabulary.\n",
    "\n",
    "        Args:\n",
    "            vocab (dict): A dictionary mapping strings (tokens) to integer IDs.\n",
    "        \"\"\"\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i: s for s, i in vocab.items()}\n",
    "\n",
    "    def encode(self, text: str) -> list[int]:\n",
    "        \"\"\"\n",
    "        Encodes a string of text into a list of integer IDs.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text to encode.\n",
    "\n",
    "        Returns:\n",
    "            list[int]: A list of integer IDs representing the text.\n",
    "        \"\"\"\n",
    "        # Split the text into tokens based on punctuation, special characters, and whitespace\n",
    "        preprocessed = re.split(r'(--|[,.?_!\"()\\'\\s])', text)\n",
    "        \n",
    "        # Clean up the tokens by removing leading/trailing whitespace and empty strings\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        \n",
    "        # Convert the tokens to their corresponding integer IDs\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids: list[int]) -> str:\n",
    "        \"\"\"\n",
    "        Decodes a list of integer IDs back into a string of text.\n",
    "\n",
    "        Args:\n",
    "            ids (list[int]): The list of integer IDs to decode.\n",
    "\n",
    "        Returns:\n",
    "            str: The decoded text.\n",
    "        \"\"\"\n",
    "        # Convert the integer IDs back to their string tokens and join them with spaces\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        \n",
    "        # Refine the spacing around punctuation for better readability\n",
    "        # This removes the space before certain punctuation marks\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13242945",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2697b8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[998, 606, 5, 751]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"the last, painted\"\n",
    "ids = tokenizer.encode(text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5710c393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the last, painted'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = tokenizer.decode(ids)\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff64e96c",
   "metadata": {},
   "source": [
    "## Adding special context to tokens for unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d163d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens.extend(['<|endoftext|>', '|unk|'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48fb7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(all_tokens)\n",
    "vocab = {token: integer for integer, token in enumerate(all_tokens)}\n",
    "inverse_vocab = {integer: token for token, integer in vocab.items()}\n",
    "token_ids = [vocab[token] for token in preprossed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4c60850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1142"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "989b5599",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    \"\"\"\n",
    "    An improved tokenizer that handles unknown words with special tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab: dict):\n",
    "        \"\"\"\n",
    "        Initializes the tokenizer with a vocabulary.\n",
    "\n",
    "        Args:\n",
    "            vocab (dict): A dictionary mapping strings (tokens) to integer IDs.\n",
    "        \"\"\"\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i: s for s, i in vocab.items()}\n",
    "        self.unk_token = \"|unk|\"  # Unknown token\n",
    "        self.unk_id = vocab.get(self.unk_token, None)\n",
    "        \n",
    "        if self.unk_token not in vocab:\n",
    "            raise ValueError(f\"Unknown token '{self.unk_token}' not found in vocabulary\")\n",
    "\n",
    "    def encode(self, text: str) -> list[int]:\n",
    "        \"\"\"\n",
    "        Encodes a string of text into a list of integer IDs.\n",
    "        Unknown tokens are replaced with |unk| token.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text to encode.\n",
    "\n",
    "        Returns:\n",
    "            list[int]: A list of integer IDs representing the text.\n",
    "        \"\"\"\n",
    "        # Split the text into tokens based on punctuation, special characters, and whitespace\n",
    "        preprocessed = re.split(r'(--|[,.?_!\"()\\'\\s])', text)\n",
    "        \n",
    "        # Clean up the tokens by removing leading/trailing whitespace and empty strings\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        \n",
    "        # Convert the tokens to their corresponding integer IDs\n",
    "        # Use unk_id for unknown tokens\n",
    "        ids = []\n",
    "        for token in preprocessed:\n",
    "            if token in self.str_to_int:\n",
    "                ids.append(self.str_to_int[token])\n",
    "            else:\n",
    "                ids.append(self.unk_id)  # Use unknown token ID\n",
    "                print(f\"Unknown token '{token}' replaced with '{self.unk_token}'\")\n",
    "        \n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids: list[int]) -> str:\n",
    "        \"\"\"\n",
    "        Decodes a list of integer IDs back into a string of text.\n",
    "\n",
    "        Args:\n",
    "            ids (list[int]): The list of integer IDs to decode.\n",
    "\n",
    "        Returns:\n",
    "            str: The decoded text.\n",
    "        \"\"\"\n",
    "        # Convert the integer IDs back to their string tokens and join them with spaces\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        \n",
    "        # Refine the spacing around punctuation for better readability\n",
    "        # This removes the space before certain punctuation marks\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "414b27ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown token 'hii' replaced with '|unk|'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown token 'hii' replaced with '|unk|'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1141, 5, 751]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer2 = SimpleTokenizerV2(vocab)\n",
    "text = \"hii, painted\"\n",
    "ids = tokenizer2.encode(text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed499b6f",
   "metadata": {},
   "source": [
    "## Byte pair encoding for unknown words (GPT-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b123ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97093134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496, 995, 0, 770, 318, 257, 1332, 13]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = \"Hello world! This is a test.\"\n",
    "ids = tokenizer.encode(text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986313f4",
   "metadata": {},
   "source": [
    "## Data Sampling (Slinding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "103ec4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        \n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i : i + max_length]\n",
    "            target_chunk = token_ids[i + 1 : i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e8ad021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=2, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "    \n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e9c4bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x191dfa274d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=4, shuffle=False)\n",
    "data_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c4e681",
   "metadata": {},
   "source": [
    "## Token IDs -> Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eed9389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = torch.nn.Embedding(6, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20143023",
   "metadata": {},
   "source": [
    "##  Encoding word position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d03a299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embeddings shape: torch.Size([1, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = torch.nn.Embedding(50257, 256)\n",
    "sample_batch = next(iter(data_loader))\n",
    "input_ids, target_ids = sample_batch\n",
    "token_embeddings = embedding_layer(input_ids)\n",
    "print(f\"Token embeddings shape: {token_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91f9834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "029b61ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc6d60b",
   "metadata": {},
   "source": [
    "adding positional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a67d74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "\n",
    "torch.arange(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44312b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0882,  0.8422, -0.1900,  ...,  0.3308,  1.1273, -0.5850],\n",
       "        [-2.2515, -0.2265,  0.8153,  ..., -0.1192,  0.9164, -1.5032],\n",
       "        [-0.9874, -0.0549,  1.1247,  ..., -0.9028,  1.6452, -1.6121],\n",
       "        [-1.2688,  0.2812, -0.7250,  ...,  0.7938,  1.4585,  0.7849]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embedding_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f7a4e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1879,  1.5505,  1.4508,  ...,  0.0181,  0.2490, -0.7247],\n",
       "         [-1.6031,  0.4306,  2.1332,  ...,  0.2283,  2.7367, -1.8855],\n",
       "         [-2.4975,  0.1889,  1.6259,  ..., -0.8247,  2.3048, -1.8709],\n",
       "         [-1.2407,  1.0132,  0.2476,  ...,  1.2262,  1.1266,  0.4753]],\n",
       "\n",
       "        [[ 0.2672,  0.6528, -0.4702,  ...,  1.0625,  1.1461, -1.7359],\n",
       "         [ 0.1705,  0.6709,  0.5932,  ..., -0.0230,  3.5569, -0.5557],\n",
       "         [-1.4279,  1.2836,  1.2024,  ..., -0.5989,  1.6410, -2.7031],\n",
       "         [-0.5465, -0.6491, -0.0436,  ...,  1.5701,  0.3883,  0.2506]],\n",
       "\n",
       "        [[-1.5198,  1.7940,  0.2928,  ...,  2.5478,  1.5441,  0.7969],\n",
       "         [-3.1444,  0.5730,  1.5750,  ...,  0.5923,  1.7345, -1.0223],\n",
       "         [-0.2617, -0.6974,  0.4352,  ..., -1.3193,  2.1155, -1.2549],\n",
       "         [-0.2747,  0.3835, -2.1807,  ...,  0.5485, -0.2894,  0.2769]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.8697,  0.0685, -2.0448,  ..., -0.1349,  0.4763, -1.1620],\n",
       "         [-1.8411,  0.4762,  0.4682,  ...,  0.8928,  1.0936, -0.4954],\n",
       "         [-3.0042, -0.4531,  0.4865,  ..., -0.2939,  0.9258, -0.9158],\n",
       "         [-1.2056,  1.5116, -1.4328,  ..., -0.3861,  1.4929,  0.6669]],\n",
       "\n",
       "        [[-1.6485,  0.1697,  0.5155,  ..., -0.9497,  0.2705,  0.6632],\n",
       "         [-1.4530, -0.8379, -0.1040,  ...,  0.5722,  0.0897, -0.4748],\n",
       "         [-0.2006, -1.8072,  2.2894,  ..., -1.8697,  1.4978, -0.6311],\n",
       "         [-2.8799, -0.5184,  0.7737,  ...,  2.1949,  0.7700,  0.0509]],\n",
       "\n",
       "        [[ 0.6986, -0.9102,  0.9746,  ..., -0.6362,  0.9799,  0.3960],\n",
       "         [-3.7921,  1.1622,  1.8592,  ...,  1.9644,  1.6940, -1.7249],\n",
       "         [-0.5801,  0.6307,  2.0234,  ..., -1.0656,  3.4645, -1.4845],\n",
       "         [-1.2056,  0.2429, -0.4799,  ...,  3.6574,  1.9888,  0.1383]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embedding = pos_embedding_layer(torch.arange(max_length))\n",
    "token_embeddings.shape\n",
    "input_embeddings = token_embeddings + pos_embedding\n",
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde528e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
